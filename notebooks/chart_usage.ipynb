{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View your lifelog data usage trends!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/tanujvasudeva/Documents/GitHub/kt-limitless/.venv/lib/python3.13/site-packages (2.2.3)\n",
      "Requirement already satisfied: matplotlib in /Users/tanujvasudeva/Documents/GitHub/kt-limitless/.venv/lib/python3.13/site-packages (3.10.1)\n",
      "Requirement already satisfied: requests in /Users/tanujvasudeva/Documents/GitHub/kt-limitless/.venv/lib/python3.13/site-packages (2.32.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Users/tanujvasudeva/Documents/GitHub/kt-limitless/.venv/lib/python3.13/site-packages (from pandas) (2.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/tanujvasudeva/Documents/GitHub/kt-limitless/.venv/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/tanujvasudeva/Documents/GitHub/kt-limitless/.venv/lib/python3.13/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/tanujvasudeva/Documents/GitHub/kt-limitless/.venv/lib/python3.13/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/tanujvasudeva/Documents/GitHub/kt-limitless/.venv/lib/python3.13/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/tanujvasudeva/Documents/GitHub/kt-limitless/.venv/lib/python3.13/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/tanujvasudeva/Documents/GitHub/kt-limitless/.venv/lib/python3.13/site-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/tanujvasudeva/Documents/GitHub/kt-limitless/.venv/lib/python3.13/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/tanujvasudeva/Documents/GitHub/kt-limitless/.venv/lib/python3.13/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /Users/tanujvasudeva/Documents/GitHub/kt-limitless/.venv/lib/python3.13/site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/tanujvasudeva/Documents/GitHub/kt-limitless/.venv/lib/python3.13/site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/tanujvasudeva/Documents/GitHub/kt-limitless/.venv/lib/python3.13/site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/tanujvasudeva/Documents/GitHub/kt-limitless/.venv/lib/python3.13/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/tanujvasudeva/Documents/GitHub/kt-limitless/.venv/lib/python3.13/site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/tanujvasudeva/Documents/GitHub/kt-limitless/.venv/lib/python3.13/site-packages (from requests) (2025.1.31)\n",
      "Requirement already satisfied: six>=1.5 in /Users/tanujvasudeva/Documents/GitHub/kt-limitless/.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas matplotlib requests\n",
    "# Set your API key\n",
    "# API_KEY = \"< your api key >\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # imports and definitions\n",
    "\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import requests\n",
    "# from datetime import date\n",
    "\n",
    "# def download_lifelogs(date_str=None, page_size=10):\n",
    "#     \"\"\"\n",
    "#     Download lifelogs from the Limitless API with pagination.\n",
    "    \n",
    "#     Args:\n",
    "#         date_str: Date in YYYY-MM-DD format (default: today)\n",
    "        \n",
    "#     Returns:\n",
    "#         DataFrame with lifelog data including timestamps\n",
    "#     \"\"\"\n",
    "#     # Use today's date if none provided\n",
    "#     if date_str is None:\n",
    "#         date_str = date.today().isoformat()\n",
    "        \n",
    "#     # API endpoint from the schema\n",
    "#     url = \"https://api.limitless.ai/v1/lifelogs\"\n",
    "    \n",
    "#     # Parameters based on the API schema\n",
    "#     params = {\n",
    "#         \"date\": date_str,\n",
    "#         \"timezone\": \"America/Chicago\",\n",
    "#         \"includeMarkdown\": \"false\",  # We only need timestamps, not content\n",
    "#         \"direction\": \"asc\",\n",
    "#         \"limit\": page_size,\n",
    "#         \"includeHeadings\": \"false\" # We only need transcript lines, not headings\n",
    "#     }\n",
    "    \n",
    "#     # Replace with your actual auth method\n",
    "#     headers = {\n",
    "#         \"X-API-Key\": API_KEY\n",
    "#     }\n",
    "    \n",
    "#     all_lifelogs = []\n",
    "    \n",
    "#     while True:\n",
    "#         # Make the API request\n",
    "#         response = requests.get(url, params=params, headers=headers)\n",
    "        \n",
    "#         # Check if request was successful\n",
    "#         if response.status_code != 200:\n",
    "#             raise Exception(f\"API request failed with status code {response.status_code}: {response.text}\")\n",
    "        \n",
    "#         # Parse the response\n",
    "#         data = response.json()\n",
    "        \n",
    "#         # Extract lifelogs from the response structure\n",
    "#         lifelogs = data.get('data', {}).get('lifelogs', [])\n",
    "        \n",
    "#         # If no more lifelogs, break the loop\n",
    "#         if not lifelogs:\n",
    "#             break\n",
    "            \n",
    "#         all_lifelogs.extend(lifelogs)\n",
    "        \n",
    "#         # Update offset for the next page\n",
    "#         next_cursor = data.get('meta', {}).get('lifelogs', {}).get('nextCursor', None)\n",
    "#         if next_cursor:\n",
    "#             params[\"cursor\"] = next_cursor\n",
    "#         else:\n",
    "#             break\n",
    "    \n",
    "#     # Create a list to store the data\n",
    "#     lifelog_data = []\n",
    "    \n",
    "#     # Extract first and last start times from each lifelog\n",
    "#     for log in all_lifelogs:\n",
    "#         if 'contents' in log and log['contents']:\n",
    "#             # Only process if there are contents\n",
    "#             first_time = None\n",
    "#             last_time = None\n",
    "            \n",
    "#             first_time = log['contents'][0]['startTime']\n",
    "#             last_time = log['contents'][-1]['startTime']\n",
    "#             lifelog_data.append({\n",
    "#                 'first_timestamp': first_time,\n",
    "#                 'last_timestamp': last_time\n",
    "#             })\n",
    "    \n",
    "#     # Create DataFrame from the collected data\n",
    "#     df = pd.DataFrame(lifelog_data)\n",
    "    \n",
    "#     # Convert timestamps to datetime objects\n",
    "#     if not df.empty:\n",
    "#         df['first_timestamp'] = pd.to_datetime(df['first_timestamp'])\n",
    "#         df['last_timestamp'] = pd.to_datetime(df['last_timestamp'])\n",
    "    \n",
    "#     return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports and definitions\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from datetime import date\n",
    "\n",
    "def download_lifelogs(date_str=None, page_size=10):\n",
    "    \"\"\"\n",
    "    Download lifelogs from the Limitless API with pagination.\n",
    "    \n",
    "    Args:\n",
    "        date_str: Date in YYYY-MM-DD format (default: today)\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with lifelog data including timestamps\n",
    "    \"\"\"\n",
    "    # Use today's date if none provided\n",
    "    if date_str is None:\n",
    "        date_str = date.today().isoformat()\n",
    "    \n",
    "    convex_url = os.getenv(\"CONVEX_URL\", \"\").strip()\n",
    "    if convex_url == \"\":\n",
    "        raise ValueError(\"CONVEX_URL environment variable is not set\")\n",
    "    \n",
    "    # Remove trailing slash if present\n",
    "    if convex_url.endswith(\"/\"):\n",
    "        convex_url = convex_url[:-1]\n",
    "    \n",
    "    # Ensure URL contains .cloud\n",
    "    if not convex_url.endswith(\".cloud\"):\n",
    "        raise ValueError(\"CONVEX_URL must be a valid Convex deployment URL (ending with .cloud)\")\n",
    "    \n",
    "    # Convert from .cloud to .site for HTTP routes\n",
    "    deployment_url = convex_url.replace(\".cloud\", \".site\")\n",
    "    \n",
    "    # API endpoint for lifelogs\n",
    "    url = f\"{deployment_url}/v1/lifelogs\"\n",
    "    \n",
    "    # Parameters based on the API schema\n",
    "    params = {\n",
    "        \"date\": date_str,\n",
    "        \"timezone\": \"America/Chicago\",\n",
    "        \"includeMarkdown\": \"false\",  # We only need timestamps, not content\n",
    "        \"direction\": \"asc\",\n",
    "        \"limit\": page_size,\n",
    "        \"includeHeadings\": \"false\" # We only need transcript lines, not headings\n",
    "    }\n",
    "    \n",
    "    # Replace with your actual auth method\n",
    "    headers = None\n",
    "    \n",
    "    all_lifelogs = []\n",
    "    \n",
    "    while True:\n",
    "        # Make the API request\n",
    "        response = requests.get(url, params=params, headers=headers)\n",
    "        \n",
    "        # Check if request was successful\n",
    "        if response.status_code != 200:\n",
    "            raise Exception(f\"API request failed with status code {response.status_code}: {response.text}\")\n",
    "        \n",
    "        # Parse the response\n",
    "        data = response.json()\n",
    "        \n",
    "        # Extract lifelogs from the response structure\n",
    "        lifelogs = data.get('data', {}).get('lifelogs', [])\n",
    "        \n",
    "        # If no more lifelogs, break the loop\n",
    "        if not lifelogs:\n",
    "            break\n",
    "            \n",
    "        all_lifelogs.extend(lifelogs)\n",
    "        \n",
    "        # Update offset for the next page\n",
    "        next_cursor = data.get('meta', {}).get('lifelogs', {}).get('nextCursor', None)\n",
    "        if next_cursor:\n",
    "            params[\"cursor\"] = next_cursor\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    # Create a list to store the data\n",
    "    lifelog_data = []\n",
    "    \n",
    "    # Extract first and last start times from each lifelog\n",
    "    for log in all_lifelogs:\n",
    "        if 'contents' in log and log['contents']:\n",
    "            # Only process if there are contents\n",
    "            first_time = None\n",
    "            last_time = None\n",
    "            \n",
    "            first_time = log['startTime']\n",
    "            last_time = log['endTime']\n",
    "            lifelog_data.append({\n",
    "                'first_timestamp': first_time,\n",
    "                'last_timestamp': last_time\n",
    "            })\n",
    "    \n",
    "    # Create DataFrame from the collected data\n",
    "    df = pd.DataFrame(lifelog_data)\n",
    "    \n",
    "    # Convert timestamps to datetime objects\n",
    "    if not df.empty:\n",
    "        df['first_timestamp'] = pd.to_datetime(df['first_timestamp'])\n",
    "        df['last_timestamp'] = pd.to_datetime(df['last_timestamp'])\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'startTime'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df = \u001b[43mdownload_lifelogs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpage_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m250\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 93\u001b[39m, in \u001b[36mdownload_lifelogs\u001b[39m\u001b[34m(date_str, page_size)\u001b[39m\n\u001b[32m     90\u001b[39m first_time = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     91\u001b[39m last_time = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m first_time = \u001b[43mlog\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcontents\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mstartTime\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     94\u001b[39m last_time = log[\u001b[33m'\u001b[39m\u001b[33mcontents\u001b[39m\u001b[33m'\u001b[39m][-\u001b[32m1\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mstartTime\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     95\u001b[39m lifelog_data.append({\n\u001b[32m     96\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mfirst_timestamp\u001b[39m\u001b[33m'\u001b[39m: first_time,\n\u001b[32m     97\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mlast_timestamp\u001b[39m\u001b[33m'\u001b[39m: last_time\n\u001b[32m     98\u001b[39m })\n",
      "\u001b[31mKeyError\u001b[39m: 'startTime'"
     ]
    }
   ],
   "source": [
    "df = download_lifelogs(page_size=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'startTime'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Download the lifelogs\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df = \u001b[43mdownload_lifelogs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpage_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m250\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Check if we have data\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m df.empty:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 93\u001b[39m, in \u001b[36mdownload_lifelogs\u001b[39m\u001b[34m(date_str, page_size)\u001b[39m\n\u001b[32m     90\u001b[39m first_time = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     91\u001b[39m last_time = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m first_time = \u001b[43mlog\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcontents\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mstartTime\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     94\u001b[39m last_time = log[\u001b[33m'\u001b[39m\u001b[33mcontents\u001b[39m\u001b[33m'\u001b[39m][-\u001b[32m1\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mstartTime\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     95\u001b[39m lifelog_data.append({\n\u001b[32m     96\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mfirst_timestamp\u001b[39m\u001b[33m'\u001b[39m: first_time,\n\u001b[32m     97\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mlast_timestamp\u001b[39m\u001b[33m'\u001b[39m: last_time\n\u001b[32m     98\u001b[39m })\n",
      "\u001b[31mKeyError\u001b[39m: 'startTime'"
     ]
    }
   ],
   "source": [
    "# Download the lifelogs\n",
    "# df = download_lifelogs(page_size=250)\n",
    "\n",
    "# Check if we have data\n",
    "if df.empty:\n",
    "    print(\"No lifelogs found for the specified date.\")\n",
    "else:\n",
    "    # Create a timeline visualization showing recording periods\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # For each lifelog, draw a horizontal line from first to last timestamp\n",
    "    for i, row in df.iterrows():\n",
    "        start_hour = row['first_timestamp'].hour + row['first_timestamp'].minute/60\n",
    "        end_hour = row['last_timestamp'].hour + row['last_timestamp'].minute/60\n",
    "        \n",
    "        # Draw a horizontal line for this recording period\n",
    "        plt.plot([start_hour, end_hour], [i, i], linewidth=3, color='blue')\n",
    "    \n",
    "    # Add labels and title\n",
    "    plt.title('Recording Periods Throughout the Day')\n",
    "    plt.xlabel('Hour of Day (24-hour format)')\n",
    "    plt.ylabel('Recording Session')\n",
    "    \n",
    "    # Format x-axis to show hours\n",
    "    plt.xticks(range(0, 25, 2))\n",
    "    plt.xlim(0, 24)\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Remove y-axis ticks since they don't represent anything specific\n",
    "    plt.yticks([])\n",
    "    \n",
    "    # Add a summary of total recording time\n",
    "    total_recording_time = sum((row['last_timestamp'] - row['first_timestamp']).total_seconds()/3600 \n",
    "                              for _, row in df.iterrows())\n",
    "    \n",
    "    # Adjust the layout to make room for the text at the bottom\n",
    "    plt.tight_layout(rect=[0, 0.05, 1, 1])\n",
    "    \n",
    "    plt.figtext(0.5, 0.01, \n",
    "                f\"Total recordings: {len(df)} | Total recording time: {total_recording_time:.2f} hours\", \n",
    "                ha=\"center\", fontsize=12)\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "    \n",
    "    # Print some basic statistics\n",
    "    earliest_recording = df['first_timestamp'].min().strftime('%H:%M')\n",
    "    latest_recording = df['last_timestamp'].max().strftime('%H:%M')\n",
    "    \n",
    "    print(f\"Total number of recording sessions: {len(df)}\")\n",
    "    print(f\"Earliest recording started at: {earliest_recording}\")\n",
    "    print(f\"Latest recording ended at: {latest_recording}\")\n",
    "    print(f\"Total recording time: {total_recording_time:.2f} hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
